{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using an LSTM-based model to predict stock returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training, validation and test periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_date = \"2008-01-01\"\n",
    "train_end_date = \"2016-12-31\"\n",
    "val_start_date = \"2017-01-01\"\n",
    "val_end_date = \"2017-12-31\"\n",
    "test_start_date = \"2018-01-01\"\n",
    "test_end_date = \"2018-12-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We'll use the data in the training period to train models, the data in the \\nvalidation period to optimize hyperparameters and the data in the test period \\nto evaluate our final model.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''We'll use the data in the training period to train models, the data in the \n",
    "validation period to optimize hyperparameters and the data in the test period \n",
    "to evaluate our final model.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and label the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezj = pd.read_csv(\"ezj.csv\", index_col=0, parse_dates=True)\n",
    "ezj[\"return\"] = ezj[\"close\"] / ezj[\"close\"].shift() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>664.908997</td>\n",
       "      <td>677.455017</td>\n",
       "      <td>654.544983</td>\n",
       "      <td>657.273010</td>\n",
       "      <td>1721833.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>651.273010</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>617.455017</td>\n",
       "      <td>632.182007</td>\n",
       "      <td>2740650.0</td>\n",
       "      <td>-0.038174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-01-04</td>\n",
       "      <td>627.817993</td>\n",
       "      <td>632.726990</td>\n",
       "      <td>590.726990</td>\n",
       "      <td>596.726990</td>\n",
       "      <td>4711938.0</td>\n",
       "      <td>-0.056084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-01-07</td>\n",
       "      <td>596.182007</td>\n",
       "      <td>597.817993</td>\n",
       "      <td>560.726990</td>\n",
       "      <td>583.091003</td>\n",
       "      <td>4103622.0</td>\n",
       "      <td>-0.022851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-01-08</td>\n",
       "      <td>567.273010</td>\n",
       "      <td>573.273010</td>\n",
       "      <td>497.782013</td>\n",
       "      <td>502.091003</td>\n",
       "      <td>12687374.0</td>\n",
       "      <td>-0.138915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close      volume  \\\n",
       "date                                                                     \n",
       "2008-01-02  664.908997  677.455017  654.544983  657.273010   1721833.0   \n",
       "2008-01-03  651.273010  654.000000  617.455017  632.182007   2740650.0   \n",
       "2008-01-04  627.817993  632.726990  590.726990  596.726990   4711938.0   \n",
       "2008-01-07  596.182007  597.817993  560.726990  583.091003   4103622.0   \n",
       "2008-01-08  567.273010  573.273010  497.782013  502.091003  12687374.0   \n",
       "\n",
       "              return  \n",
       "date                  \n",
       "2008-01-02       NaN  \n",
       "2008-01-03 -0.038174  \n",
       "2008-01-04 -0.056084  \n",
       "2008-01-07 -0.022851  \n",
       "2008-01-08 -0.138915  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ezj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We'll assign a label of 1 to dates on which EasyJet's stock return is \\npositive, and a label of 0 to dates on which it is not.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''We'll assign a label of 1 to dates on which EasyJet's stock return is \n",
    "positive, and a label of 0 to dates on which it is not.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezj[\"label\"] = np.where(ezj[\"return\"] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To predict the labels, we'll use returns and volumes from the past 30 \\ntrading days. To reduce the chances of getting stuck in local optima, we'll \\nstandardize the returns using statistics computed over the training period, \\nand the volumes using a sliding window approach.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To predict the labels, we'll use returns and volumes from the past 30 \n",
    "trading days. To reduce the chances of getting stuck in local optima, we'll \n",
    "standardize the returns using statistics computed over the training period, \n",
    "and the volumes using a sliding window approach.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezj[\"std_return\"] = (ezj[\"return\"] - ezj[\"return\"][:val_start_date].mean()) / ezj[\"return\"][:val_start_date].std()\n",
    "ezj[\"std_volume\"] = (ezj[\"volume\"] - ezj[\"volume\"].rolling(50).mean()) / ezj[\"volume\"].rolling(50).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezj.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Before creating generators for the train, validation and test sets, we \\nneed the integer locations corresponding to the start of the validation and \\ntest periods.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Before creating generators for the train, validation and test sets, we \n",
    "need the integer locations corresponding to the start of the validation and \n",
    "test periods.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_start_iloc = ezj.index.get_loc(val_start_date, method=\"bfill\")\n",
    "test_start_iloc = ezj.index.get_loc(test_start_date, method=\"bfill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We'll use TimeseriesGenerator to create the generators, and pass \\nlength=30 so that data from the past 30 trading days is used to make \\npredictions.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''We'll use TimeseriesGenerator to create the generators, and pass \n",
    "length=30 so that data from the past 30 trading days is used to make \n",
    "predictions.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = TimeseriesGenerator(ezj[[\"std_return\", \"std_volume\"]].values, ezj[[\"label\"]].values,\n",
    "                                      length=30, batch_size=64, end_index=val_start_iloc-1)\n",
    "val_generator = TimeseriesGenerator(ezj[[\"std_return\", \"std_volume\"]].values, ezj[[\"label\"]].values,\n",
    "                                    length=30, batch_size=64, start_index=val_start_iloc,\n",
    "                                    end_index=test_start_iloc-1)\n",
    "test_generator = TimeseriesGenerator(ezj[[\"std_return\", \"std_volume\"]].values, ezj[[\"label\"]].values,\n",
    "                                     length=30, batch_size=64, start_index=test_start_iloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `model_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model_fn trains an LSTM-based model for a maximum of 100 epochs, stopping \\nearly if validation accuracy does not improve for 5 epochs. If you don't have \\na GPU, make sure to swap CuDNNLSTM for LSTM.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model_fn trains an LSTM-based model for a maximum of 100 epochs, stopping \n",
    "early if validation accuracy does not improve for 5 epochs. If you don't have \n",
    "a GPU, make sure to swap CuDNNLSTM for LSTM.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(params):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(params[\"lstm_size\"], input_shape=(30, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(params[\"dropout\"]))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(params[\"learning_rate\"]),\n",
    "                  loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=5,\n",
    "                                                  restore_best_weights=True)]\n",
    "    history = model.fit_generator(train_generator, validation_data=val_generator,\n",
    "                                  callbacks=callbacks, epochs=100, verbose=0).history\n",
    "    return (history, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `random_search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We'll use random_search to optimize hyperparameters, which runs a random \\nsearch and saves the results and best model in search_dir.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''We'll use random_search to optimize hyperparameters, which runs a random \n",
    "search and saves the results and best model in search_dir.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(model_fn, search_space, n_iter, search_dir):\n",
    "    results = []\n",
    "    os.mkdir(search_dir)\n",
    "    best_model_path = os.path.join(search_dir, \"best_model.h5\")\n",
    "    results_path = os.path.join(search_dir, \"results.csv\")\n",
    "    for i in range(n_iter):\n",
    "        params = {k: v[np.random.randint(len(v))] for k, v in search_space.items()}\n",
    "        history, model = model_fn(params)\n",
    "        epochs = np.argmax(history[\"val_acc\"]) + 1\n",
    "        result = {k: v[epochs - 1] for k, v in history.items()}\n",
    "        params[\"epochs\"] = epochs\n",
    "        if i == 0:\n",
    "            best_val_acc = result[\"val_acc\"]\n",
    "            model.save(best_model_path)\n",
    "        if result[\"val_acc\"] > best_val_acc:\n",
    "            best_val_acc = result[\"val_acc\"]\n",
    "            model.save(best_model_path)\n",
    "        result = {**params, **result}\n",
    "        results.append(result)\n",
    "        tf.keras.backend.clear_session()\n",
    "        print(f\"iteration {i + 1} – {', '.join(f'{k}:{v:.4g}' for k, v in result.items())}\")\n",
    "    best_model = tf.keras.models.load_model(best_model_path)\n",
    "    results = pd.DataFrame(results)\n",
    "    results.to_csv(results_path)\n",
    "    return (results, best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We'll run the random search for 200 iterations. It should take somewhere \\nbetween 10 and 90 minutes to complete, depending on your hardware.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''We'll run the random search for 200 iterations. It should take somewhere \n",
    "between 10 and 90 minutes to complete, depending on your hardware.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\"lstm_size\": np.linspace(50, 200, 16, dtype=int),\n",
    "                \"dropout\": np.linspace(0, 0.4, 9),\n",
    "                \"learning_rate\": np.linspace(0.004, 0.01, 13)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-37-4122b83171cf>:12: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    }
   ],
   "source": [
    "results, best_model = random_search(model_fn, search_space, 200, \"search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.sort_values(\"val_acc\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''All that's left is to evaluate our final model over the test period.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model.evaluate_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
